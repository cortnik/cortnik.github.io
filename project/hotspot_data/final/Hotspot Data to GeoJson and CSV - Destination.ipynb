{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.517</td>\n",
       "      <td>46.776</td>\n",
       "      <td>20404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.517</td>\n",
       "      <td>46.890</td>\n",
       "      <td>16208</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.517</td>\n",
       "      <td>46.890</td>\n",
       "      <td>16208</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.524</td>\n",
       "      <td>46.710</td>\n",
       "      <td>18805</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.525</td>\n",
       "      <td>46.648</td>\n",
       "      <td>11072</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1      2  ID\n",
       "0  24.517  46.776  20404   1\n",
       "1  24.517  46.890  16208   2\n",
       "2  24.517  46.890  16208   3\n",
       "3  24.524  46.710  18805   4\n",
       "4  24.525  46.648  11072   5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NODES FOR PNU\n",
    "nodes_df = pd.read_csv(\"CDRHourly_Flows/towers_index.txt\", header = None)\n",
    "\n",
    "#to get only lat & long from nodes_df \n",
    "len(nodes_df[[0,1]])\n",
    "\n",
    "points = nodes_df[[0,1]]\n",
    "import scipy.spatial as spsp\n",
    "tree = spsp.cKDTree(points)\n",
    "list_nodesnoID = tree.query_ball_point([24.852, 46.723], 0.005)\n",
    "#to add 1 so that index = cell ID. (see Data_structures doc)\n",
    "list_nodes =[x+1 for x in list_nodesnoID]\n",
    "\n",
    "nodes_df['ID'] = nodes_df.index + 1\n",
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DEFINING THE FUNCTION THAT PRINTS GEOJSONS\n",
    "\n",
    "import json\n",
    "def df_to_geojson(df, properties, lat='latitude', lon='longitude'):\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "    for _, row in df.iterrows():\n",
    "        feature = {'type':'Feature',\n",
    "                   'properties':{},\n",
    "                   'geometry':{'type':'Point',\n",
    "                               'coordinates':[]}}\n",
    "        feature['geometry']['coordinates'] = [row[2],row[1]]\n",
    "        for prop in properties:\n",
    "            feature['properties'][prop] = row[prop]\n",
    "        geojson['features'].append(feature)\n",
    "    return geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#6:00AM\n",
    "\n",
    "df_06=pd.read_csv(\"CDRHourly_Flows/Rn_OD_6-7.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_06[(df_06.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"6:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_0607.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_0607.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7:00AM\n",
    "\n",
    "df_07=pd.read_csv(\"CDRHourly_Flows/Rn_OD_7-8.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_07[(df_07.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"7:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_0708.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_0708.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#7:00AM\n",
    "\n",
    "df_08=pd.read_csv(\"CDRHourly_Flows/Rn_OD_8-9.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_08[(df_08.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"8:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_0809.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_0809.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9:00AM\n",
    "\n",
    "df_09=pd.read_csv(\"CDRHourly_Flows/Rn_OD_9-10.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_09[(df_09.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"9:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_0910.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_0910.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#10:00AM\n",
    "\n",
    "df_10=pd.read_csv(\"CDRHourly_Flows/Rn_OD_10-11.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_10[(df_10.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"10:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1011.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#11:00AM\n",
    "\n",
    "df_11=pd.read_csv(\"CDRHourly_Flows/Rn_OD_11-12.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_11[(df_11.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"11:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1112.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1112.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#12:00AM\n",
    "\n",
    "df_12=pd.read_csv(\"CDRHourly_Flows/Rn_OD_12-13.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_12[(df_12.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"12:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1213.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1213.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#13:00\n",
    "\n",
    "df_13=pd.read_csv(\"CDRHourly_Flows/Rn_OD_13-14.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_13[(df_13.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"13:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1314.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1314.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#14:00\n",
    "\n",
    "df_14=pd.read_csv(\"CDRHourly_Flows/Rn_OD_14-15.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_14[(df_14.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"14:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1415.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1415.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#15:00\n",
    "\n",
    "df_15=pd.read_csv(\"CDRHourly_Flows/Rn_OD_15-16.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_15[(df_15.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"15:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1516.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1516.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#16:00\n",
    "\n",
    "df_16=pd.read_csv(\"CDRHourly_Flows/Rn_OD_16-17.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_16[(df_16.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"16:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1617.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1617.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#17:00\n",
    "\n",
    "df_17=pd.read_csv(\"CDRHourly_Flows/Rn_OD_17-18.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_17[(df_17.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"17:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1718.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1718.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#18:00\n",
    "\n",
    "df_18=pd.read_csv(\"CDRHourly_Flows/Rn_OD_18-19.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_18[(df_18.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"18:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1819.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1819.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#19:00\n",
    "\n",
    "df_19=pd.read_csv(\"CDRHourly_Flows/Rn_OD_19-20.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_19[(df_19.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"19:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_1920.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_1920.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#20:00\n",
    "\n",
    "df_20=pd.read_csv(\"CDRHourly_Flows/Rn_OD_20-21.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_20[(df_20.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"20:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_2021.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#21:00\n",
    "\n",
    "df_21=pd.read_csv(\"CDRHourly_Flows/Rn_OD_21-22.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_21[(df_21.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"21:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_2122.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_2122.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#22:00\n",
    "\n",
    "df_22=pd.read_csv(\"CDRHourly_Flows/Rn_OD_22-23.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_22[(df_22.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"22:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_2223.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_2223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#23:00\n",
    "\n",
    "df_23=pd.read_csv(\"CDRHourly_Flows/Rn_OD_23-24.txt\", header=None, \n",
    "               names=['oid', 'did', 'close_rid_origin', 'close_rid_dest', 'flow'])\n",
    "\n",
    "df_PND = df_23[(df_23.isin({'did':list_nodes}).any(1))]\n",
    "df_PND = df_PND.drop('close_rid_origin',1)\n",
    "df_PND = df_PND.drop('close_rid_dest',1)\n",
    "\n",
    "#Join hourly flow info with specified nodes to get destinations around PNU \n",
    "# df_PND is flows to PNU i.e. PNU is the destination of flows  \n",
    "df_PND_xy =pd.merge(df_PND, nodes_df[[0,1,'ID']], left_on = 'oid', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy.rename(columns={0: 'lat_origin', 1: 'long_origin'}, inplace=True)\n",
    "df_PND_xy2 =pd.merge(df_PND_xy, nodes_df[[0,1,'ID']], left_on = 'did', right_on = 'ID', how = 'inner')\n",
    "df_PND_xy2.rename(columns={0: 'lat_dest', 1: 'long_dest'}, inplace=True)\n",
    "#drop the 'ID' columns to get a clean dataframe \n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_x',1)\n",
    "df_PND_xy2 = df_PND_xy2.drop('ID_y',1)\n",
    "\n",
    "#creating a new dataframe that only has the did and flow\n",
    "\n",
    "df_PND_xy_active = df_PND_xy2.drop([u'did', u'lat_origin', u'long_origin'], 1)\n",
    "df_PND_xy_active2=(df_PND_xy_active.groupby(['oid','lat_dest', 'long_dest']).sum().reset_index())\n",
    "df_PND_xy_active2['hour']=\"23:00\"\n",
    "\n",
    "\n",
    "#PRINTING THE FILES\n",
    "\n",
    "cols = ['oid', 'lat_dest', 'long_dest', 'flow', 'hour']\n",
    "geojson = df_to_geojson(df_PND_xy_active2, cols)\n",
    "\n",
    "output_filename = 'PNDhotspot_2324.geojson'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2) \n",
    "    \n",
    "\n",
    "df_PND_xy_active2.to_csv('PNDhotspot_2324.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
